{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de2aec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 22:49:32.935485: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744400972.947025   16632 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744400972.950490   16632 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744400972.960507   16632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744400972.960518   16632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744400972.960519   16632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744400972.960521   16632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 22:49:32.963769: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================\n",
      "Training on dataset: /media/leo/Huy/Project/CARS/AMZ/Arts & Photography\n",
      "user_field_M 689607\n",
      "item_field_M 201822\n",
      "field_M 891429\n",
      "item_bind_M 143815\n",
      "user_bind_M 147825\n",
      "# of training: 346226\n",
      "# of test: 147825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744400988.487532   16632 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5678 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:08:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/training/adagrad.py:138: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1744400989.005670   16632 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial evaluation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 22:49:59.995804: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.53GiB (rounded to 4859830272)requested by op einsum_5/Einsum\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-04-11 22:49:59.995818: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1058] BFCAllocator dump for GPU_0_bfc\n",
      "2025-04-11 22:49:59.995823: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (256): \tTotal Chunks: 10, Chunks in use: 10. 2.5KiB allocated for chunks. 2.5KiB in use in bin. 800B client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995825: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (512): \tTotal Chunks: 2, Chunks in use: 1. 1.0KiB allocated for chunks. 512B in use in bin. 264B client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995828: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995830: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995832: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (4096): \tTotal Chunks: 1, Chunks in use: 0. 5.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995834: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995836: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995839: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (32768): \tTotal Chunks: 2, Chunks in use: 2. 66.0KiB allocated for chunks. 66.0KiB in use in bin. 66.0KiB client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995841: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995842: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995844: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995846: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (524288): \tTotal Chunks: 2, Chunks in use: 2. 1.32MiB allocated for chunks. 1.32MiB in use in bin. 1.32MiB client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995849: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 1. 1.23MiB allocated for chunks. 1.23MiB in use in bin. 788.4KiB client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995851: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (2097152): \tTotal Chunks: 2, Chunks in use: 2. 5.26MiB allocated for chunks. 5.26MiB in use in bin. 5.26MiB client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995853: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995855: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995857: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995859: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (33554432): \tTotal Chunks: 3, Chunks in use: 3. 133.79MiB allocated for chunks. 133.79MiB in use in bin. 121.69MiB client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995862: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (67108864): \tTotal Chunks: 2, Chunks in use: 1. 179.78MiB allocated for chunks. 64.00MiB in use in bin. 49.27MiB client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995865: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995867: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (268435456): \tTotal Chunks: 3, Chunks in use: 2. 832.55MiB allocated for chunks. 512.00MiB in use in bin. 336.72MiB client-requested in use in bin.\n",
      "2025-04-11 22:49:59.995875: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1081] Bin for 4.53GiB was 256.00MiB, Chunk State: \n",
      "2025-04-11 22:49:59.995881: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1087]   Size: 320.55MiB | Requested Size: 561.8KiB | in_use: 0 | bin_num: 20, prev:   Size: 33.0KiB | Requested Size: 33.0KiB | in_use: 1 | bin_num: -1, next:   Size: 36.21MiB | Requested Size: 36.21MiB | in_use: 1 | bin_num: -1\n",
      "2025-04-11 22:49:59.995883: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1094] Next region of size 536870912\n",
      "2025-04-11 22:49:59.995886: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c1930000000 of size 2758656 next 15\n",
      "2025-04-11 22:49:59.995888: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c19302a1800 of size 575488 next 16\n",
      "2025-04-11 22:49:59.995889: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c193032e000 of size 256 next 17\n",
      "2025-04-11 22:49:59.995891: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c193032e100 of size 256 next 18\n",
      "2025-04-11 22:49:59.995892: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c193032e200 of size 256 next 19\n",
      "2025-04-11 22:49:59.995893: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c193032e300 of size 256 next 20\n",
      "2025-04-11 22:49:59.995895: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] Free  at 7c193032e400 of size 512 next 33\n",
      "2025-04-11 22:49:59.995897: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c193032e600 of size 512 next 27\n",
      "2025-04-11 22:49:59.995898: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] Free  at 7c193032e800 of size 5120 next 25\n",
      "2025-04-11 22:49:59.995899: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c193032fc00 of size 33792 next 37\n",
      "2025-04-11 22:49:59.995901: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] Free  at 7c1930338000 of size 336118272 next 38\n",
      "2025-04-11 22:49:59.995902: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c19443c4200 of size 37967616 next 30\n",
      "2025-04-11 22:49:59.995910: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c19467f9900 of size 33792 next 24\n",
      "2025-04-11 22:49:59.995911: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c1946801d00 of size 37967616 next 34\n",
      "2025-04-11 22:49:59.995913: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] Free  at 7c1948c37400 of size 121408512 next 18446744073709551615\n",
      "2025-04-11 22:49:59.995918: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1094] Next region of size 268435456\n",
      "2025-04-11 22:49:59.995919: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c1950000000 of size 268435456 next 18446744073709551615\n",
      "2025-04-11 22:49:59.995920: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1094] Next region of size 268435456\n",
      "2025-04-11 22:49:59.995922: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c1960000000 of size 268435456 next 18446744073709551615\n",
      "2025-04-11 22:49:59.995923: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1094] Next region of size 67108864\n",
      "2025-04-11 22:49:59.995925: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c1980000000 of size 2758656 next 9\n",
      "2025-04-11 22:49:59.995933: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c19802a1800 of size 64350208 next 18446744073709551615\n",
      "2025-04-11 22:49:59.995934: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1094] Next region of size 67108864\n",
      "2025-04-11 22:49:59.995936: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c1984000000 of size 67108864 next 18446744073709551615\n",
      "2025-04-11 22:49:59.995937: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1094] Next region of size 2097152\n",
      "2025-04-11 22:49:59.995939: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c19dfc00000 of size 256 next 1\n",
      "2025-04-11 22:49:59.995940: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c19dfc00100 of size 256 next 2\n",
      "2025-04-11 22:49:59.995942: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c19dfc00200 of size 256 next 3\n",
      "2025-04-11 22:49:59.995943: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c19dfc00300 of size 256 next 4\n",
      "2025-04-11 22:49:59.995944: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c19dfc00400 of size 256 next 5\n",
      "2025-04-11 22:49:59.995946: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c19dfc00500 of size 807424 next 6\n",
      "2025-04-11 22:49:59.995948: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c19dfcc5700 of size 256 next 11\n",
      "2025-04-11 22:49:59.995949: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c19dfcc5800 of size 1280 next 12\n",
      "2025-04-11 22:49:59.995951: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7c19dfcc5d00 of size 1286912 next 18446744073709551615\n",
      "2025-04-11 22:49:59.995952: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1119]      Summary of in-use Chunks by size: \n",
      "2025-04-11 22:49:59.995955: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 10 Chunks of size 256 totalling 2.5KiB\n",
      "2025-04-11 22:49:59.995957: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 1 Chunks of size 512 totalling 512B\n",
      "2025-04-11 22:49:59.995958: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2025-04-11 22:49:59.995960: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 2 Chunks of size 33792 totalling 66.0KiB\n",
      "2025-04-11 22:49:59.995962: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 1 Chunks of size 575488 totalling 562.0KiB\n",
      "2025-04-11 22:49:59.995964: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 1 Chunks of size 807424 totalling 788.5KiB\n",
      "2025-04-11 22:49:59.995966: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 1 Chunks of size 1286912 totalling 1.23MiB\n",
      "2025-04-11 22:49:59.995967: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 2 Chunks of size 2758656 totalling 5.26MiB\n",
      "2025-04-11 22:49:59.995969: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 2 Chunks of size 37967616 totalling 72.42MiB\n",
      "2025-04-11 22:49:59.995971: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 1 Chunks of size 64350208 totalling 61.37MiB\n",
      "2025-04-11 22:49:59.995973: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 1 Chunks of size 67108864 totalling 64.00MiB\n",
      "2025-04-11 22:49:59.995974: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 2 Chunks of size 268435456 totalling 512.00MiB\n",
      "2025-04-11 22:49:59.995976: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1126] Sum Total of in-use chunks: 717.66MiB\n",
      "2025-04-11 22:49:59.995978: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1128] Total bytes in pool: 1210056704 memory_limit_: 5954142208 available bytes: 4744085504 curr_region_allocation_bytes_: 1073741824\n",
      "2025-04-11 22:49:59.995982: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1133] Stats: \n",
      "Limit:                      5954142208\n",
      "InUse:                       752524288\n",
      "MaxInUse:                   1008712704\n",
      "NumAllocs:                          51\n",
      "MaxAllocSize:                268435456\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-04-11 22:49:59.995985: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:512] *___________________________*******_________***************xxxxxxx****************xxxxxx************\n",
      "2025-04-11 22:49:59.995998: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at einsum_op_impl.h:533 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[66,128,143816] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "2025-04-11 22:49:59.996012: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[66,128,143816] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node einsum_5/Einsum}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "2025-04-11 22:49:59.996019: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[66,128,143816] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node einsum_5/Einsum}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "\t [[einsum_6/Einsum/_9]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "2025-04-11 22:49:59.996033: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 6288157852398697635\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'einsum_5/Einsum' defined at (most recent call last):\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/runpy.py\", line 87, in _run_code\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/asyncio/events.py\", line 80, in _run\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n    File \"/tmp/ipykernel_16632/2218588336.py\", line 304, in <module>\n    File \"/tmp/ipykernel_16632/2218588336.py\", line 273, in _build_graph\n    File \"/tmp/ipykernel_16632/2218588336.py\", line 252, in _pre\nNode: 'einsum_5/Einsum'\nDetected at node 'einsum_5/Einsum' defined at (most recent call last):\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/runpy.py\", line 87, in _run_code\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/asyncio/events.py\", line 80, in _run\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n    File \"/tmp/ipykernel_16632/2218588336.py\", line 304, in <module>\n    File \"/tmp/ipykernel_16632/2218588336.py\", line 273, in _build_graph\n    File \"/tmp/ipykernel_16632/2218588336.py\", line 252, in _pre\nNode: 'einsum_5/Einsum'\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[66,128,143816] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node einsum_5/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[einsum_6/Einsum/_9]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[66,128,143816] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node einsum_5/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'einsum_5/Einsum':\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/runpy.py\", line 87, in _run_code\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/asyncio/events.py\", line 80, in _run\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n  File \"/tmp/ipykernel_16632/2218588336.py\", line 304, in <module>\n  File \"/tmp/ipykernel_16632/2218588336.py\", line 273, in _build_graph\n  File \"/tmp/ipykernel_16632/2218588336.py\", line 252, in _pre\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 1260, in op_dispatch_handler\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/ops/special_math_ops.py\", line 763, in einsum\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/ops/special_math_ops.py\", line 1200, in _einsum_v2\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/ops/gen_linalg_ops.py\", line 1134, in einsum\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 796, in _apply_op_helper\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 2705, in _create_op_internal\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1200, in from_node_def\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/client/session.py:1407\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1407\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/client/session.py:1390\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/client/session.py:1483\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1482\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1483\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[66,128,143816] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node einsum_5/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[einsum_6/Einsum/_9]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[66,128,143816] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node einsum_5/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 366\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# Initial evaluation\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial evaluation:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 366\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m# Begin training epochs\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mepochs):\n",
      "Cell \u001b[0;32mIn[1], line 333\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    331\u001b[0m batch_users \u001b[38;5;241m=\u001b[39m end_index \u001b[38;5;241m-\u001b[39m start_index\n\u001b[1;32m    332\u001b[0m feed_dict_eval \u001b[38;5;241m=\u001b[39m { deep\u001b[38;5;241m.\u001b[39minput_u: u_batch_eval, deep\u001b[38;5;241m.\u001b[39mdropout_keep_prob: \u001b[38;5;241m1.0\u001b[39m }\n\u001b[0;32m--> 333\u001b[0m pre \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m pre \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(pre)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Remove the dummy padding dimension\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/client/session.py:977\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    974\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 977\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    980\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/client/session.py:1220\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1220\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1223\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/client/session.py:1400\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1397\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1400\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1401\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1403\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/client/session.py:1426\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monly supports NHWC tensor format\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m message:\n\u001b[1;32m   1422\u001b[0m   message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mA possible workaround: Try disabling Grappler optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1423\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mby modifying the config for creating the session eg.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1424\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124msession_config.graph_options.rewrite_options.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1425\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_meta_optimizer = True\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1426\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(node_def, op, message)\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'einsum_5/Einsum' defined at (most recent call last):\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/runpy.py\", line 87, in _run_code\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/asyncio/events.py\", line 80, in _run\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n    File \"/tmp/ipykernel_16632/2218588336.py\", line 304, in <module>\n    File \"/tmp/ipykernel_16632/2218588336.py\", line 273, in _build_graph\n    File \"/tmp/ipykernel_16632/2218588336.py\", line 252, in _pre\nNode: 'einsum_5/Einsum'\nDetected at node 'einsum_5/Einsum' defined at (most recent call last):\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/runpy.py\", line 87, in _run_code\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/asyncio/events.py\", line 80, in _run\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n    File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n    File \"/tmp/ipykernel_16632/2218588336.py\", line 304, in <module>\n    File \"/tmp/ipykernel_16632/2218588336.py\", line 273, in _build_graph\n    File \"/tmp/ipykernel_16632/2218588336.py\", line 252, in _pre\nNode: 'einsum_5/Einsum'\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[66,128,143816] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node einsum_5/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[einsum_6/Einsum/_9]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[66,128,143816] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node einsum_5/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'einsum_5/Einsum':\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/runpy.py\", line 87, in _run_code\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/asyncio/events.py\", line 80, in _run\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n  File \"/tmp/ipykernel_16632/2218588336.py\", line 304, in <module>\n  File \"/tmp/ipykernel_16632/2218588336.py\", line 273, in _build_graph\n  File \"/tmp/ipykernel_16632/2218588336.py\", line 252, in _pre\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 1260, in op_dispatch_handler\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/ops/special_math_ops.py\", line 763, in einsum\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/ops/special_math_ops.py\", line 1200, in _einsum_v2\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/ops/gen_linalg_ops.py\", line 1134, in einsum\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 796, in _apply_op_helper\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 2705, in _create_op_internal\n  File \"/home/leo/miniconda3/envs/ENSFM/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1200, in from_node_def\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.sparse\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random_seed = 2019\n",
    "np.random.seed(random_seed)\n",
    "tf.compat.v1.set_random_seed(random_seed)\n",
    "\n",
    "# Define training arguments and hyperparameters\n",
    "class Args:\n",
    "    dataset = 'dummy'\n",
    "    verbose = 10\n",
    "    batch_size = 512\n",
    "    epochs = 101  # adjust epochs as needed; 101 used here for demonstration\n",
    "    embed_size = 64\n",
    "    lr = 0.05\n",
    "    dropout = 0.9\n",
    "    negative_weight = 0.05\n",
    "    topK = [5, 10, 20]\n",
    "\n",
    "args = Args()\n",
    "\n",
    "###############################################################################\n",
    "# Data Loader\n",
    "###############################################################################\n",
    "class LoadData(object):\n",
    "    def __init__(self, DATA_ROOT):\n",
    "        self.trainfile = os.path.join(DATA_ROOT, 'train.csv')\n",
    "        self.testfile = os.path.join(DATA_ROOT, 'test.csv')\n",
    "        self.user_field_M, self.item_field_M = self.get_length()\n",
    "        print(\"user_field_M\", self.user_field_M)\n",
    "        print(\"item_field_M\", self.item_field_M)\n",
    "        print(\"field_M\", self.user_field_M + self.item_field_M)\n",
    "        self.item_bind_M = self.bind_item()  # assign a unique id for each item feature string\n",
    "        self.user_bind_M = self.bind_user()  # assign a unique id for each user feature string\n",
    "        print(\"item_bind_M\", len(self.binded_items))\n",
    "        print(\"user_bind_M\", len(self.binded_users))\n",
    "        self.item_map_list = []\n",
    "        # Build an item feature list from the map (using the string split on '-' to get the individual features)\n",
    "        for itemid in self.item_map:\n",
    "            self.item_map_list.append([int(feature) for feature in self.item_map[itemid].strip().split('-')])\n",
    "        # Append a dummy feature vector for padding\n",
    "        self.item_map_list.append([int(feature) for feature in self.item_map[0].strip().split('-')])\n",
    "        self.user_positive_list = self.get_positive_list(self.trainfile)  # map: user_id -> list of positive item ids\n",
    "        self.Train_data, self.Test_data = self.construct_data()\n",
    "        self.user_train, self.item_train = self.get_train_instances()\n",
    "        self.user_test = self.get_test()\n",
    "\n",
    "    def get_length(self):\n",
    "        length_user = 0\n",
    "        length_item = 0\n",
    "        with open(self.trainfile, 'r') as f:\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                user_features = line.strip().split(',')[0].split('-')\n",
    "                item_features = line.strip().split(',')[1].split('-')\n",
    "                for uf in user_features:\n",
    "                    feature = int(uf)\n",
    "                    if feature > length_user:\n",
    "                        length_user = feature\n",
    "                for itf in item_features:\n",
    "                    feature = int(itf)\n",
    "                    if feature > length_item:\n",
    "                        length_item = feature\n",
    "                line = f.readline()\n",
    "        return length_user + 1, length_item + 1\n",
    "\n",
    "    def bind_item(self):\n",
    "        self.binded_items = {}  # map: item feature string -> id\n",
    "        self.item_map = {}      # map: id -> item feature string\n",
    "        self.bind_i(self.trainfile)\n",
    "        self.bind_i(self.testfile)\n",
    "        return len(self.binded_items)\n",
    "\n",
    "    def bind_i(self, file):\n",
    "        with open(file, 'r') as f:\n",
    "            line = f.readline()\n",
    "            i = len(self.binded_items)\n",
    "            while line:\n",
    "                features = line.strip().split(',')\n",
    "                item_features = features[1]\n",
    "                if item_features not in self.binded_items:\n",
    "                    self.binded_items[item_features] = i\n",
    "                    self.item_map[i] = item_features\n",
    "                    i += 1\n",
    "                line = f.readline()\n",
    "\n",
    "    def bind_user(self):\n",
    "        self.binded_users = {}  # map: user feature string -> id\n",
    "        self.user_map = {}      # map: id -> user feature string\n",
    "        self.bind_u(self.trainfile)\n",
    "        self.bind_u(self.testfile)\n",
    "        return len(self.binded_users)\n",
    "\n",
    "    def bind_u(self, file):\n",
    "        with open(file, 'r') as f:\n",
    "            line = f.readline()\n",
    "            i = len(self.binded_users)\n",
    "            while line:\n",
    "                features = line.strip().split(',')\n",
    "                user_features = features[0]\n",
    "                if user_features not in self.binded_users:\n",
    "                    self.binded_users[user_features] = i\n",
    "                    self.user_map[i] = user_features\n",
    "                    i += 1\n",
    "                line = f.readline()\n",
    "\n",
    "    def get_positive_list(self, file):\n",
    "        self.max_positive_len = 0\n",
    "        user_positive_list = {}\n",
    "        with open(file, 'r') as f:\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                features = line.strip().split(',')\n",
    "                user_id = self.binded_users[features[0]]\n",
    "                item_id = self.binded_items[features[1]]\n",
    "                if user_id in user_positive_list:\n",
    "                    user_positive_list[user_id].append(item_id)\n",
    "                else:\n",
    "                    user_positive_list[user_id] = [item_id]\n",
    "                line = f.readline()\n",
    "        for u in user_positive_list:\n",
    "            if len(user_positive_list[u]) > self.max_positive_len:\n",
    "                self.max_positive_len = len(user_positive_list[u])\n",
    "        return user_positive_list\n",
    "\n",
    "    def get_train_instances(self):\n",
    "        user_train, item_train = [], []\n",
    "        for u in self.user_positive_list:\n",
    "            # Transform user features into a list of ints\n",
    "            u_train = [int(feature) for feature in self.user_map[u].strip().split('-')]\n",
    "            user_train.append(u_train)\n",
    "            temp = self.user_positive_list[u][:]\n",
    "            # Pad the list with a dummy item id (which is self.item_bind_M) to reach max_positive_len\n",
    "            while len(temp) < self.max_positive_len:\n",
    "                temp.append(self.item_bind_M)\n",
    "            item_train.append(temp)\n",
    "        user_train = np.array(user_train)\n",
    "        item_train = np.array(item_train)\n",
    "        return user_train, item_train\n",
    "\n",
    "    def construct_data(self):\n",
    "        X_user, X_item = self.read_data(self.trainfile)\n",
    "        Train_data = self.construct_dataset(X_user, X_item)\n",
    "        print(\"# of training:\", len(X_user))\n",
    "        X_user, X_item = self.read_data(self.testfile)\n",
    "        Test_data = self.construct_dataset(X_user, X_item)\n",
    "        print(\"# of test:\", len(X_user))\n",
    "        return Train_data, Test_data\n",
    "\n",
    "    def construct_dataset(self, X_user, X_item):\n",
    "        user_id = []\n",
    "        for one in X_user:\n",
    "            key = \"-\".join([str(item) for item in one])\n",
    "            user_id.append(self.binded_users[key])\n",
    "        item_id = []\n",
    "        for one in X_item:\n",
    "            key = \"-\".join([str(item) for item in one])\n",
    "            item_id.append(self.binded_items[key])\n",
    "        count = np.ones(len(X_user))\n",
    "        sparse_matrix = scipy.sparse.csr_matrix((count, (user_id, item_id)), dtype=np.int16,\n",
    "                                                shape=(self.user_bind_M, self.item_bind_M))\n",
    "        return sparse_matrix\n",
    "\n",
    "    def get_test(self):\n",
    "        X_user, _ = self.read_data(self.testfile)\n",
    "        return X_user\n",
    "\n",
    "    def read_data(self, file):\n",
    "        X_user = []\n",
    "        X_item = []\n",
    "        with open(file, 'r') as f:\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                features = line.strip().split(',')\n",
    "                user_features = features[0].split('-')\n",
    "                X_user.append([int(item) for item in user_features])\n",
    "                item_features = features[1].split('-')\n",
    "                X_item.append([int(item) for item in item_features])\n",
    "                line = f.readline()\n",
    "        return X_user, X_item\n",
    "\n",
    "###############################################################################\n",
    "# ENSFM Model\n",
    "###############################################################################\n",
    "class ENSFM:\n",
    "    def __init__(self, item_attribute, user_field_M, item_field_M, embedding_size, max_item_pu, args):\n",
    "        self.embedding_size = embedding_size\n",
    "        self.max_item_pu = max_item_pu\n",
    "        self.user_field_M = user_field_M\n",
    "        self.item_field_M = item_field_M\n",
    "        self.weight1 = args.negative_weight\n",
    "        self.item_attribute = item_attribute  # a list of item feature vectors\n",
    "        self.lambda_bilinear = [0.0, 0.0]\n",
    "\n",
    "    def _create_placeholders(self):\n",
    "        self.input_u = tf.compat.v1.placeholder(tf.int32, [None, None], name=\"input_u_feature\")\n",
    "        self.input_ur = tf.compat.v1.placeholder(tf.int32, [None, self.max_item_pu], name=\"input_ur\")\n",
    "        self.dropout_keep_prob = tf.compat.v1.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "\n",
    "    def _create_variables(self):\n",
    "        self.uidW = tf.Variable(tf.random.truncated_normal([self.user_field_M, self.embedding_size],\n",
    "                                                             mean=0.0, stddev=0.01), name=\"uidW\")\n",
    "        self.iidW = tf.Variable(tf.random.truncated_normal([self.item_field_M+1, self.embedding_size],\n",
    "                                                             mean=0.0, stddev=0.01), name=\"iidW\")\n",
    "        self.H_i = tf.Variable(tf.constant(0.01, shape=[self.embedding_size, 1]), name=\"H_i\")\n",
    "        self.H_s = tf.Variable(tf.constant(0.01, shape=[self.embedding_size, 1]), name=\"H_s\")\n",
    "        self.u_bias = tf.Variable(tf.random.truncated_normal([self.user_field_M, 1],\n",
    "                                                               mean=0.0, stddev=0.01), name=\"u_bias\")\n",
    "        self.i_bias = tf.Variable(tf.random.truncated_normal([self.item_field_M, 1],\n",
    "                                                               mean=0.0, stddev=0.01), name=\"i_bias\")\n",
    "        self.bias = tf.Variable(tf.constant(0.0), name='bias')\n",
    "\n",
    "    def _create_vectors(self):\n",
    "        self.user_feature_emb = tf.nn.embedding_lookup(self.uidW, self.input_u)\n",
    "        self.summed_user_emb = tf.reduce_sum(self.user_feature_emb, axis=1)\n",
    "        # Apply dropout to H_i and H_s\n",
    "        self.H_i = tf.nn.dropout(self.H_i, rate=1 - self.dropout_keep_prob)\n",
    "        self.H_s = tf.nn.dropout(self.H_s, rate=1 - self.dropout_keep_prob)\n",
    "        self.all_item_feature_emb = tf.nn.embedding_lookup(self.iidW, self.item_attribute)\n",
    "        self.summed_all_item_emb = tf.reduce_sum(self.all_item_feature_emb, axis=1)\n",
    "        # Compute cross terms for user and item\n",
    "        self.user_cross = 0.5 * (tf.square(self.summed_user_emb) - tf.reduce_sum(tf.square(self.user_feature_emb), axis=1))\n",
    "        self.item_cross = 0.5 * (tf.square(self.summed_all_item_emb) - tf.reduce_sum(tf.square(self.all_item_feature_emb), axis=1))\n",
    "        self.user_cross_score = tf.matmul(self.user_cross, self.H_s)\n",
    "        self.item_cross_score = tf.matmul(self.item_cross, self.H_s)\n",
    "        self.user_bias = tf.reduce_sum(tf.nn.embedding_lookup(self.u_bias, self.input_u), axis=1)\n",
    "        self.item_bias = tf.reduce_sum(tf.nn.embedding_lookup(self.i_bias, self.item_attribute), axis=1)\n",
    "        self.I = tf.ones(shape=(tf.shape(self.input_u)[0], 1))\n",
    "        self.p_emb = tf.concat([self.summed_user_emb, self.user_cross_score + self.user_bias + self.bias, self.I], axis=1)\n",
    "        self.I = tf.ones(shape=(tf.shape(self.summed_all_item_emb)[0], 1))\n",
    "        self.q_emb = tf.concat([self.summed_all_item_emb, self.I, self.item_cross_score + self.item_bias], axis=1)\n",
    "        self.H_i_emb = tf.concat([self.H_i, [[1.0]], [[1.0]]], axis=0)\n",
    "\n",
    "    def _create_inference(self):\n",
    "        self.pos_item = tf.nn.embedding_lookup(self.q_emb, self.input_ur)\n",
    "        # Filter out padding values (assumed to equal self.item_bind_M)\n",
    "        self.pos_num_r = tf.cast(tf.not_equal(self.input_ur, data.item_bind_M), tf.float32)\n",
    "        self.pos_item = tf.einsum('ab,abc->abc', self.pos_num_r, self.pos_item)\n",
    "        self.pos_r = tf.einsum('ac,abc->abc', self.p_emb, self.pos_item)\n",
    "        self.pos_r = tf.einsum('ajk,kl->ajl', self.pos_r, self.H_i_emb)\n",
    "        self.pos_r = tf.reshape(self.pos_r, [-1, self.max_item_pu])\n",
    "\n",
    "    def _pre(self):\n",
    "        dot = tf.einsum('ac,bc->abc', self.p_emb, self.q_emb)\n",
    "        pre = tf.einsum('ajk,kl->aj', dot, self.H_i_emb)\n",
    "        return pre\n",
    "\n",
    "    def _create_loss(self):\n",
    "        self.loss1 = self.weight1 * tf.reduce_sum(\n",
    "            tf.reduce_sum(tf.reduce_sum(tf.einsum('ab,ac->abc', self.q_emb, self.q_emb), axis=0)\n",
    "                          * tf.reduce_sum(tf.einsum('ab,ac->abc', self.p_emb, self.p_emb), axis=0)\n",
    "                          * tf.matmul(self.H_i_emb, self.H_i_emb, transpose_b=True), axis=0), axis=0)\n",
    "        self.loss1 += tf.reduce_sum((1.0 - self.weight1) * tf.square(self.pos_r) - 2.0 * self.pos_r)\n",
    "        self.l2_loss0 = tf.nn.l2_loss(self.uidW)\n",
    "        self.l2_loss1 = tf.nn.l2_loss(self.iidW)\n",
    "        self.loss = self.loss1 + self.lambda_bilinear[0] * self.l2_loss0 + self.lambda_bilinear[1] * self.l2_loss1\n",
    "        self.reg_loss = self.lambda_bilinear[0] * self.l2_loss0 + self.lambda_bilinear[1] * self.l2_loss1\n",
    "\n",
    "    def _build_graph(self):\n",
    "        self._create_placeholders()\n",
    "        self._create_variables()\n",
    "        self._create_vectors()\n",
    "        self._create_inference()\n",
    "        self._create_loss()\n",
    "        self.pre = self._pre()\n",
    "\n",
    "###############################################################################\n",
    "# List of dataset directories\n",
    "###############################################################################\n",
    "# Change the base directory to where your datasets are stored.\n",
    "base_data_dir = \"/media/leo/Huy/Project/CARS/AMZ\"\n",
    "dataset_dirs = [\n",
    "    os.path.join(base_data_dir, \"Arts & Photography\"),\n",
    "    os.path.join(base_data_dir, \"Genre Fiction\"),\n",
    "    os.path.join(base_data_dir, \"History\")\n",
    "]\n",
    "\n",
    "###############################################################################\n",
    "# Training Loop\n",
    "###############################################################################\n",
    "for DATA_ROOT in dataset_dirs:\n",
    "    print(\"==============================================\")\n",
    "    print(\"Training on dataset:\", DATA_ROOT)\n",
    "    \n",
    "    # Load data for the current dataset\n",
    "    data = LoadData(DATA_ROOT)\n",
    "    \n",
    "    # Start a new TensorFlow graph for each dataset\n",
    "    with tf.Graph().as_default():\n",
    "        session_conf = tf.compat.v1.ConfigProto()\n",
    "        session_conf.gpu_options.allow_growth = True\n",
    "        with tf.compat.v1.Session(config=session_conf) as sess:\n",
    "            # Build the model\n",
    "            deep = ENSFM(data.item_map_list, data.user_field_M, data.item_field_M,\n",
    "                         args.embed_size, data.max_positive_len, args)\n",
    "            deep._build_graph()\n",
    "            train_op1 = tf.compat.v1.train.AdagradOptimizer(\n",
    "                learning_rate=args.lr, initial_accumulator_value=1e-8\n",
    "            ).minimize(deep.loss)\n",
    "            sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "            # Define inner helper functions that use the current session and model\n",
    "            def train_step1(u_batch, y_batch):\n",
    "                feed_dict = {\n",
    "                    deep.input_u: u_batch,\n",
    "                    deep.input_ur: y_batch,\n",
    "                    deep.dropout_keep_prob: args.dropout,\n",
    "                }\n",
    "                _, loss, loss1, loss2, _ = sess.run(\n",
    "                    [train_op1, deep.loss, deep.loss1, deep.reg_loss, deep.p_emb],\n",
    "                    feed_dict)\n",
    "                return loss, loss1, loss2\n",
    "\n",
    "            def evaluate():\n",
    "                eva_batch = 128\n",
    "                recall_all, ndcg_all = [[] for _ in range(3)], [[] for _ in range(3)]\n",
    "                user_features = data.user_test\n",
    "                ll = int(len(user_features) / eva_batch) + 1\n",
    "                for batch_num in range(ll):\n",
    "                    start_index = batch_num * eva_batch\n",
    "                    end_index = min((batch_num + 1) * eva_batch, len(user_features))\n",
    "                    u_batch_eval = user_features[start_index:end_index]\n",
    "                    batch_users = end_index - start_index\n",
    "                    feed_dict_eval = { deep.input_u: u_batch_eval, deep.dropout_keep_prob: 1.0 }\n",
    "                    pre = sess.run(deep.pre, feed_dict_eval)\n",
    "                    pre = np.array(pre)\n",
    "                    # Remove the dummy padding dimension\n",
    "                    pre = np.delete(pre, -1, axis=1)\n",
    "                    user_ids = [data.binded_users[\"-\".join(map(str, one))] for one in u_batch_eval]\n",
    "                    \n",
    "                    idx = np.zeros_like(pre, dtype=bool)\n",
    "                    idx[data.Train_data[user_ids].nonzero()] = True\n",
    "                    pre[idx] = -np.inf\n",
    "\n",
    "                    for i, kj in enumerate(args.topK):\n",
    "                        idx_topk_part = np.argpartition(-pre, kj, axis=1)\n",
    "                        pre_bin = np.zeros_like(pre, dtype=bool)\n",
    "                        pre_bin[np.arange(batch_users)[:, None], idx_topk_part[:, :kj]] = True\n",
    "                        true_bin = np.zeros_like(pre, dtype=bool)\n",
    "                        true_bin[data.Test_data[user_ids].nonzero()] = True\n",
    "                        tmp = (np.logical_and(true_bin, pre_bin).sum(axis=1)).astype(np.float32)\n",
    "                        recall_all[i].append(tmp / np.minimum(kj, true_bin.sum(axis=1)))\n",
    "                        topk_part = pre[np.arange(batch_users)[:, None], idx_topk_part[:, :kj]]\n",
    "                        idx_part = np.argsort(-topk_part, axis=1)\n",
    "                        idx_topk = idx_topk_part[np.arange(batch_users)[:, None], idx_part]\n",
    "                        tp = np.log(2) / np.log(np.arange(2, kj + 2))\n",
    "                        test_batch = data.Test_data[user_ids]\n",
    "                        DCG = (test_batch[np.arange(batch_users)[:, None], idx_topk].toarray() * tp).sum(axis=1)\n",
    "                        IDCG = np.array([(tp[:min(n, kj)]).sum() for n in test_batch.getnnz(axis=1)])\n",
    "                        ndcg_all[i].append(DCG / IDCG)\n",
    "                for i in range(3):\n",
    "                    recall_all[i] = np.hstack(recall_all[i])\n",
    "                    ndcg_all[i] = np.hstack(ndcg_all[i])\n",
    "                    print(f\"Top {args.topK[i]} Recall: {np.mean(recall_all[i]):.4f}, NDCG: {np.mean(ndcg_all[i]):.4f}\")\n",
    "\n",
    "            # Initial evaluation\n",
    "            print(\"Initial evaluation:\")\n",
    "            evaluate()\n",
    "\n",
    "            # Begin training epochs\n",
    "            for epoch in range(args.epochs):\n",
    "                print(f\"\\nEpoch {epoch} for dataset {DATA_ROOT}\")\n",
    "                # Shuffle training data at each epoch\n",
    "                shuffle_indices = np.random.permutation(len(data.user_train))\n",
    "                data.user_train = data.user_train[shuffle_indices]\n",
    "                data.item_train = data.item_train[shuffle_indices]\n",
    "                ll = int(len(data.user_train) / args.batch_size)\n",
    "                loss_sum = np.zeros(3)\n",
    "                for batch_num in range(ll):\n",
    "                    start_index = batch_num * args.batch_size\n",
    "                    end_index = min((batch_num + 1) * args.batch_size, len(data.user_train))\n",
    "                    u_batch = data.user_train[start_index:end_index]\n",
    "                    i_batch = data.item_train[start_index:end_index]\n",
    "                    loss, loss1, loss2 = train_step1(u_batch, i_batch)\n",
    "                    loss_sum += np.array([loss, loss1, loss2])\n",
    "                print(f\"Epoch {epoch} losses: loss={loss_sum[0]/ll:.4f}, loss1={loss_sum[1]/ll:.4f}, reg={loss_sum[2]/ll:.4f}\")\n",
    "\n",
    "                if epoch % args.verbose == 0:\n",
    "                    print(\"Evaluation:\")\n",
    "                    evaluate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENSFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
